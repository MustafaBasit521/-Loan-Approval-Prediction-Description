# -Loan-Approval-Prediction-Description
Loan Default Prediction ğŸ¦
ğŸ“Œ Project Overview

This project focuses on building a machine learning model to predict loan default status (approved/rejected). It uses borrower and loan-related features to classify whether a person is likely to default or not.

ğŸ“‚ Dataset

The dataset contains the following features:

person_age â€“ Age of the borrower

person_income â€“ Annual income of the borrower

person_home_ownership â€“ Home ownership status

person_emp_length â€“ Employment length (in years)

loan_intent â€“ Purpose of the loan (e.g., education, personal, medical)

loan_grade â€“ Loan grade assigned by the lender

loan_amnt â€“ Loan amount requested

loan_int_rate â€“ Interest rate of the loan

loan_percent_income â€“ Ratio of loan amount to borrowerâ€™s income

cb_person_default_on_file â€“ Whether borrower has defaulted before (Yes/No)

cb_person_cred_hist_length â€“ Length of credit history

Target Label:

loan_status â†’ (0 = Loan Approved, 1 = Loan Defaulted)

âš™ï¸ Preprocessing Steps

Handling Missing Values

Filled categorical NaNs with mode.

Filled numerical NaNs with median.

Encoding Categorical Features

Applied One-Hot Encoding for person_home_ownership, loan_intent, and cb_person_default_on_file.

Balancing the Dataset

Observed class imbalance (more approved loans than defaults).

Used two approaches:

class_weight="balanced" â†’ Adjusts weights inversely proportional to class frequencies.

SMOTE (Synthetic Minority Oversampling Technique) â†’ Generates synthetic samples for the minority class.

ğŸ¤– Models Used

Logistic Regression

Decision Tree Classifier

Both models were trained and evaluated with:

Baseline (imbalanced data)

Class Weight balancing

SMOTE oversampling

ğŸ“Š Evaluation Metrics

Accuracy

Precision

Recall

F1 Score

Confusion Matrix

ğŸ”‘ Since this is a loan default problem, Recall (True Positive Rate) is especially important.
Catching defaulters (1s) is more critical than just maximizing accuracy.

ğŸ“ˆ Results

Logistic Regression and Decision Tree both achieved around 91% accuracy on baseline.

With class_weight="balanced", recall for defaulters improved but at the cost of precision.

With SMOTE, recall improved further, making the model better at detecting defaults.

Trade-off:

Balanced models reduce bias towards majority class.

Higher recall ensures fewer risky borrowers are misclassified as safe.

âœ… Conclusion

Best approach: Use SMOTE + Logistic Regression (better recall, stable accuracy).

In real-world banking, catching potential defaulters is more important than overall accuracy.

This project demonstrates:

Understanding of imbalanced classification problems.

Use of resampling techniques (SMOTE) and class weights.

Clear evaluation with precision, recall, F1, and confusion matrix.

ğŸ“Œ Future Improvements

Hyperparameter tuning (GridSearchCV / RandomizedSearchCV).

Try ensemble methods (Random Forest, XGBoost).

Deploy as an API for real-time loan approval predictions.
